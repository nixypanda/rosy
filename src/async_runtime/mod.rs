//! Home-grown async runtime

use alloc::{boxed::Box, collections::BTreeMap, sync::Arc, task::Wake};
use core::{
    future::Future,
    pin::Pin,
    sync::atomic::{AtomicU64, Ordering},
    task::{Context, Poll, Waker},
};
use crossbeam_queue::ArrayQueue;

use crate::x86_64::interrupts;

static NEXT_ID: AtomicU64 = AtomicU64::new(0);
const DEFAULT_TASK_QUEUE_SIZE: usize = 100;

/// Represents an async task
///
/// It is essentially a wrapper around a "pinned" "heap allocated" "dynamically dispatched"
/// future. The return of this future is an empty type (or unit type).
pub struct Task<'a> {
    id: TaskId,
    future: Pin<Box<dyn Future<Output = ()> + 'a>>,
}

/// Execute async tasks
pub struct Executor<'a> {
    tasks: BTreeMap<TaskId, Task<'a>>,
    task_queue: Arc<ArrayQueue<TaskId>>,
    waker_cache: BTreeMap<TaskId, Waker>,
}

/// Unique task id for each task
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord)]
pub struct TaskId(u64);

/// Push the ID of the woken task to the task_queue of the executor.
struct TaskWaker {
    id: TaskId,
    queue: Arc<ArrayQueue<TaskId>>,
}

impl<'a> Task<'a> {
    /// Create a new [`Task`] from an arbitrary future.
    pub fn new(future: impl Future<Output = ()> + 'a) -> Self {
        Self {
            id: TaskId::new(),
            // Note: We pin this in memory to ensure that this can't be moved in memory as futures
            // generated by async-await can be self-referential which would be invalidated if a
            // move occures.
            future: Box::pin(future),
        }
    }

    fn poll(&mut self, context: &mut Context) -> Poll<()> {
        self.future.as_mut().poll(context)
    }
}

impl TaskId {
    // Generate a new unique task_id 
    fn new() -> Self {
        // The fetch_add method atomically increases the value and returns the previous value in
        // one atomic operation. This means that even when the TaskId::new method is called in
        // parallel, every ID is returned exactly once.
        // The Ordering parameter defines whether the compiler is allowed to reorder the fetch_add
        // operation in the instructions stream. Since we only require that the ID is unique, the
        // Relaxed ordering with the weakest requirements is enough in this case.
        TaskId(NEXT_ID.fetch_add(1, Ordering::Relaxed))
    }
}

impl TaskWaker {
    fn new(id: TaskId, queue: Arc<ArrayQueue<TaskId>>) -> Waker {
        Waker::from(Arc::new(TaskWaker { id, queue }))
    }

    fn wake_task(&self) {
        self.queue.push(self.id).expect("task_queue full");
    }
}

impl Wake for TaskWaker {
    fn wake(self: Arc<Self>) {
        self.wake_task();
    }
}

impl<'a> Executor<'a> {
    /// Create a new executor
    pub fn new() -> Self {
        Executor {
            tasks: BTreeMap::new(),
            task_queue: Arc::new(ArrayQueue::new(DEFAULT_TASK_QUEUE_SIZE)),
            waker_cache: BTreeMap::new(),
        }
    }

    /// Add a task to execution list
    ///
    /// # Panics
    /// If the queue is full it panics
    pub fn spawn(&mut self, task: Task<'a>) {
        let task_id = task.id;
        if self.tasks.insert(task.id, task).is_some() {
            panic!("Task with same id already present {:?}", task_id);
        }
        self.task_queue.push(task_id).expect("queue full");
    }

    /// Run the [`Executor`] and execute all the registerd async tasks.
    pub fn run(&mut self) -> ! {
        loop {
            self.run_ready_tasks();
            self.sleep_if_idle();
        }
    }

    /// Run tasks that are ready for execution.
    pub fn run_ready_tasks(&mut self) {
        while let Some(task_id) = self.task_queue.pop() {
            let task = match self.tasks.get_mut(&task_id) {
                Some(task) => task,
                None => continue,
            };

            let waker = self
                .waker_cache
                .entry(task_id)
                .or_insert_with(|| TaskWaker::new(task_id, self.task_queue.clone()));
            let mut context = Context::from_waker(&waker);
            match task.poll(&mut context) {
                Poll::Ready(_) => {
                    self.tasks.remove(&task_id);
                    self.waker_cache.remove(&task_id);
                }
                Poll::Pending => {}
            }
        }
    }

    fn sleep_if_idle(&self) {
        interrupts::disable();
        if self.task_queue.is_empty() {
            interrupts::enable_and_halt_cpu_till_next_one();
        } else {
            interrupts::enable();
        }
    }
}
